# ðŸ›¡ï¸ AI-Driven Driveway Safety System

### *Preventing Child Accidents Using Computer Vision*

**MSE806: Intelligent Transportation Systems â€“ Assessment 2**

---

## ðŸš— Project Overview

This project presents a smart rear-view camera system that enhances vehicle safety in residential environments. It uses advanced **computer vision** and **AI-based object detection** to identify vulnerable individualsâ€”especially **children**, **pets**, and **livestock**â€”within the vehicleâ€™s reversing path. The system provides **real-time visual and audible alerts**, significantly reducing the risk of tragic backover accidents during low-speed manoeuvres.

> ðŸ“‰ In New Zealand alone, around **five children are killed or injured annually** in driveway accidents (Otago Daily Times, 2025).

---

## ðŸŽ¯ Objectives

* Detect small or partially hidden **children**, **pets**, and **adults** during reverse operations.
* Reduce **false positives** using context-aware thresholds and configurable confidence levels.
* Offer **visual (GUI pop-ups)** and **auditory alerts**; future integration with **automatic braking systems**.
* Ensure **GDPR-compliant** local video processing without cloud dependency.

---

## ðŸ” Key Features

* âš¡ **Real-time detection** using YOLOv5n (fine-tuned with new "kids" class).
* ðŸ§’ Reliable detection of babies, toddlers, adults, and various animals.
* ðŸ“º Visual alerts via GUI (Tkinter).
* ðŸ”Š Audio alerts via PyAudio with adjustable sensitivity.
* ðŸŽ¯ Customisable **confidence threshold** and consecutive frame detection logic.
* ðŸ’» Lightweight model, deployable on **embedded hardware** (Jetson Nano, Raspberry Pi).

---

## ðŸ§  Technologies Used

| Type             | Tools/Frameworks          |
| ---------------- | ------------------------- |
| Language         | Python 3.x                |
| Object Detection | Ultralytics YOLOv5        |
| Image Processing | OpenCV                    |
| GUI              | Tkinter                   |
| Audio Alerts     | PyAudio, wave             |
| Embedded Support | Raspberry Pi, Jetson Nano |

---

## ðŸ› ï¸ System Architecture

The architecture follows a real-time edge-computing model:

1. **Rear-view camera feed** captured.
2. **YOLOv5n model** detects objects.
3. Results passed to GUI/audio handler.
4. Optional **braking system** can be triggered.

> All data remains localâ€”no video leaves the device.

---

## ðŸ§ª Model Training & Improvements

* âœ… Fine-tuned YOLOv5n using transfer learning.
* âž• Added a new custom class: **kids**.
* ðŸ—‚ï¸ Trained on a hybrid dataset (COCO + Roboflow).
* ðŸ§® Achieved strong **Precision (0.85)** and **mAP\@50 (0.86)**.
* ðŸ“Š Tested under various lighting and occlusion conditions.
* ðŸ“‰ Identified challenges: small object visibility, poor lighting.

---

## âš–ï¸ Ethical & Security Considerations

* All processing is performed **on-device**.
* No cloud storage or third-party access.
* Model retrained to reduce **bias** and enhance detection of underrepresented groups.
* Faces blurred in training data to protect privacy.

---

## ðŸ“ˆ Future Enhancements

* ðŸŒ™ Integrate **thermal or night vision** cameras for low-light conditions.
* ðŸ§  Explore newer, lightweight AI models (e.g., YOLOv8, MobileNet variants).
* ðŸ”§ Enhance robustness through **larger and more diverse datasets**.
* ðŸš¦Add **haptic feedback** and more granular driver assistance features.

---

## ðŸ“¦ Installation

### Prerequisites

* Python 3.x
* Hardware: Raspberry Pi 4 / NVIDIA Jetson Nano

### Dependencies

```bash
pip install ultralytics opencv-python pyaudio
```

> `wave` is included in Python's standard library.

---

## ðŸš€ Getting Started

```python
# Example Inference
from ultralytics import YOLO
model = YOLO("best.pt")
results = model("sample_image.jpg")
results.show()
```

---

## ðŸ“š Citation & Credits

Developed by:

* **Alfredo Jr. Albis Torrena**
* **Eunseok Choi**
* **Fabricio Mello Mulato**
* **Yan Huang**

Supervisor: *Mukesh Mishra*
Yoobee College of Creative Innovation â€“ MSE806 (ITS)

---

## ðŸ“„ License

This project is released under an **academic licence** for educational purposes only.

---

